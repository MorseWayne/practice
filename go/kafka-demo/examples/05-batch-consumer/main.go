package batchconsumer

import (
	"context"
	"encoding/json"
	"log"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	"github.com/IBM/sarama"
)

const (
	topic         = "batch-processing-topic"
	consumerGroup = "batch-consumer-group"
	batchSize     = 50 // æ‰¹å¤„ç†å¤§å°
)

type OrderEvent struct {
	OrderID    string    `json:"order_id"`
	UserID     string    `json:"user_id"`
	Amount     float64   `json:"amount"`
	Status     string    `json:"status"`
	CreateTime time.Time `json:"create_time"`
}

type BatchConsumerHandler struct {
	logger *log.Logger
}

func (h *BatchConsumerHandler) Setup(session sarama.ConsumerGroupSession) error {
	h.logger.Printf("ğŸ¯ æ–°ä¼šè¯å¼€å§‹")
	return nil
}

func (h *BatchConsumerHandler) Cleanup(session sarama.ConsumerGroupSession) error {
	h.logger.Printf("ğŸ”š ä¼šè¯ç»“æŸ")
	return nil
}

func (h *BatchConsumerHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	batch := make([]*sarama.ConsumerMessage, 0, batchSize)
	ticker := time.NewTicker(5 * time.Second) // æœ€å¤šç­‰å¾… 5 ç§’
	defer ticker.Stop()

	for {
		select {
		case message := <-claim.Messages():
			if message == nil {
				return nil
			}

			batch = append(batch, message)

			// è¾¾åˆ°æ‰¹æ¬¡å¤§å°ï¼Œç«‹å³å¤„ç†
			if len(batch) >= batchSize {
				h.processBatch(session, batch)
				batch = batch[:0]
				ticker.Reset(5 * time.Second)
			}

		case <-ticker.C:
			// è¶…æ—¶ï¼Œå¤„ç†å½“å‰æ‰¹æ¬¡ï¼ˆå³ä½¿æœªæ»¡ï¼‰
			if len(batch) > 0 {
				h.logger.Printf("â° æ‰¹æ¬¡è¶…æ—¶ï¼Œå¤„ç† %d æ¡æ¶ˆæ¯", len(batch))
				h.processBatch(session, batch)
				batch = batch[:0]
			}

		case <-session.Context().Done():
			// ä¼šè¯ç»“æŸå‰å¤„ç†å‰©ä½™æ¶ˆæ¯
			if len(batch) > 0 {
				h.logger.Printf("ğŸ”„ ä¼šè¯ç»“æŸï¼Œå¤„ç†å‰©ä½™ %d æ¡æ¶ˆæ¯", len(batch))
				h.processBatch(session, batch)
			}
			return nil
		}
	}
}

func (h *BatchConsumerHandler) processBatch(session sarama.ConsumerGroupSession, batch []*sarama.ConsumerMessage) {
	startTime := time.Now()

	h.logger.Printf("ğŸ“¦ å¼€å§‹å¤„ç†æ‰¹æ¬¡ï¼Œæ¶ˆæ¯æ•°: %d", len(batch))

	// è§£ææ‰€æœ‰æ¶ˆæ¯
	orders := make([]OrderEvent, 0, len(batch))
	for _, msg := range batch {
		var order OrderEvent
		if err := json.Unmarshal(msg.Value, &order); err != nil {
			h.logger.Printf("âŒ è§£ææ¶ˆæ¯å¤±è´¥: %v", err)
			continue
		}
		orders = append(orders, order)
	}

	// æ‰¹é‡å¤„ç†ä¸šåŠ¡é€»è¾‘
	// ä¾‹å¦‚: æ‰¹é‡æ’å…¥æ•°æ®åº“ã€æ‰¹é‡è°ƒç”¨ API ç­‰
	if err := h.batchProcess(orders); err != nil {
		h.logger.Printf("âŒ æ‰¹é‡å¤„ç†å¤±è´¥: %v", err)
		return
	}

	// æ ‡è®°æœ€åä¸€æ¡æ¶ˆæ¯
	lastMsg := batch[len(batch)-1]
	session.MarkMessage(lastMsg, "")

	duration := time.Since(startTime)
	h.logger.Printf("âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œè€—æ—¶: %v, é€Ÿç‡: %.2f æ¡/ç§’\n",
		duration, float64(len(batch))/duration.Seconds())
}

func (h *BatchConsumerHandler) batchProcess(orders []OrderEvent) error {
	// æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†
	// ä¾‹å¦‚: æ‰¹é‡å†™å…¥æ•°æ®åº“
	time.Sleep(100 * time.Millisecond)

	// ç»Ÿè®¡ä¿¡æ¯
	totalAmount := 0.0
	userMap := make(map[string]int)

	for _, order := range orders {
		totalAmount += order.Amount
		userMap[order.UserID]++
	}

	h.logger.Printf("  è®¢å•æ•°: %d, æ€»é‡‘é¢: %.2f, ç”¨æˆ·æ•°: %d",
		len(orders), totalAmount, len(userMap))

	return nil
}

func main() {
	logger := log.New(os.Stdout, "[BatchConsumer] ", log.LstdFlags)

	config := sarama.NewConfig()
	config.Version = sarama.V3_6_0_0
	config.Consumer.Return.Errors = true
	config.Consumer.Offsets.Initial = sarama.OffsetOldest // ä»å¤´å¼€å§‹
	config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategySticky
	config.Consumer.Offsets.AutoCommit.Enable = false // æ‰‹åŠ¨æäº¤

	// å¢åŠ æ‹‰å–å¤§å°ï¼Œé€‚åˆæ‰¹å¤„ç†
	config.Consumer.Fetch.Default = 1024 * 1024 // 1MB
	config.Consumer.MaxProcessingTime = 30 * time.Second

	brokers := []string{"localhost:19092", "localhost:29092", "localhost:39092"}

	logger.Println("å¯åŠ¨æ‰¹é‡æ¶ˆè´¹è€…...")
	logger.Printf("æ‰¹å¤„ç†å¤§å°: %d", batchSize)

	consumerGroup, err := sarama.NewConsumerGroup(brokers, consumerGroup, config)
	if err != nil {
		log.Fatalf("åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥: %v", err)
	}

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	handler := &BatchConsumerHandler{logger: logger}

	wg := &sync.WaitGroup{}
	wg.Add(1)
	go func() {
		defer wg.Done()
		for {
			if err := consumerGroup.Consume(ctx, []string{topic}, handler); err != nil {
				logger.Printf("æ¶ˆè´¹é”™è¯¯: %v", err)
			}
			if ctx.Err() != nil {
				return
			}
		}
	}()

	wg.Add(1)
	go func() {
		defer wg.Done()
		for err := range consumerGroup.Errors() {
			logger.Printf("âŒ æ¶ˆè´¹è€…é”™è¯¯: %v", err)
		}
	}()

	logger.Println("âœ… æ‰¹é‡æ¶ˆè´¹è€…å·²å¯åŠ¨")

	signals := make(chan os.Signal, 1)
	signal.Notify(signals, syscall.SIGINT, syscall.SIGTERM)
	<-signals

	logger.Println("æ”¶åˆ°é€€å‡ºä¿¡å·...")
	cancel()
	wg.Wait()
	consumerGroup.Close()
	logger.Println("æ‰¹é‡æ¶ˆè´¹è€…å·²å…³é—­")
}
